{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96ba5c-5fdd-4705-8bcc-2e12662015d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aicsimageio import AICSImage\n",
    "import sys\n",
    "sys.path.append(\"/pasteur/u/jmhb/confocal-2d-video-processing\")\n",
    "import segmentation_core as sc\n",
    "import seg_eval as se\n",
    "import pipeline_utils as pu\n",
    "import utils\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# project path \n",
    "c = yaml.safe_load(open(\"/pasteur/u/jmhb/confocal-2d-video-processing/config.yaml\", \"r\"))\n",
    "PATH_PROJECT = Path(c['path_project'])\n",
    "# data path\n",
    "c = yaml.safe_load(open(\"/pasteur/u/jmhb/confocal-2d-video-processing/config.yaml\", \"r\"))\n",
    "c['path_data'] = \"/pasteur/data/hiPSCs_January2022\" # hack\n",
    "PATH_DATA = Path(c['path_data'])\n",
    "# PATH_FNAMES = PATH_DATA / \"fname-lookup.csv\"\n",
    "PATH_FNAMES = PATH_DATA / \"fname-lookup-timelapse.csv\"\n",
    "# PATH_FNAMES = PATH_DATA / \"fname-lookup-zstack.csv\"\n",
    "\n",
    "PATH_SEG_FUNCS = PATH_PROJECT / \"seg-func-map.yaml\"\n",
    "PATH_EVALS = Path(\"/pasteur/u/jmhb/confocal-2d-video-processing/analyses/jan22-neural-diff/eval-pdfs\")\n",
    "\n",
    "## choose the images to segment \n",
    "channel=\"nuclei\"\n",
    "frame=50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63b2ea-09e7-470e-babf-9d75215c5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter on the paths\n",
    "if 1:\n",
    "    df_fnames = pd.read_csv(PATH_FNAMES).set_index('index')\n",
    "    df_fnames_filt = df_fnames.query(\"(g1=='D0') | (g1 in ('AP24','AP48') & g2 in ('CTRL','CTRLOAC','CTRLAC')) \")    \n",
    "else:\n",
    "    # else only remove WT since it's bad\n",
    "    df_fnames_filt = df_fnames.query(\"(g1!='WT')\")    \n",
    "\n",
    "df_fnames_filt['path_file'] = str(PATH_DATA) +\"/\"+ df_fnames_filt['folder']+\"/\"+df_fnames_filt['fname']\n",
    "print(df_fnames_filt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e0373-841d-4c55-98b3-36fb3372b2d1",
   "metadata": {},
   "source": [
    "#### load img data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca75d8d-53c4-4af9-8ca8-eedd053ac74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the middle frame \n",
    "imgs = [] \n",
    "channel='nuclei'\n",
    "for idx, row in df_fnames_filt.iterrows():\n",
    "    print(idx, end=\" \")\n",
    "    fname = row.path_file\n",
    "    img_obj = AICSImage(fname)\n",
    "    ch_idx_lookup = pu.get_channel_idx_lookup(img_obj.channel_names)\n",
    "    ch_idx = ch_idx_lookup[channel]\n",
    "    x = img_obj.get_image_data(\"TCZYX\")\n",
    "    frame = x.shape[0]//2\n",
    "    img=x[frame, ch_idx,[0]].copy()\n",
    "    print(f\"Shape {x.shape}, getting frame {frame}, ch_idx {ch_idx}\")\n",
    "\n",
    "    del x\n",
    "    imgs.append(img)\n",
    "\n",
    "lookup_idx_to_imgsidx = dict(zip(df_fnames_filt.index, np.arange(len(df_fnames_filt))))    \n",
    "imgs_D0 = np.concatenate(imgs[:32]).astype(np.float32)\n",
    "imgs_AP = np.concatenate(imgs[32:]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54737c2f-d138-4649-9d45-376f39b5ef51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59834f9-4b58-4f37-bea1-9cf9cddb3597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09287c-fc9d-412b-acbf-b84aa86a0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid \n",
    "nimgs=10\n",
    "figsize=(40,40)\n",
    "grid = make_grid(torch.Tensor(imgs_D0).unsqueeze(1), nimgs)[0]\n",
    "f,axs = plt.subplots(1,1,figsize=figsize)\n",
    "axs.imshow(grid, cmap='gray')\n",
    "plt.show()\n",
    "grid = make_grid(torch.Tensor(imgs_AP).unsqueeze(1), nimgs)[0]\n",
    "f,axs = plt.subplots(1,1,figsize=figsize)\n",
    "axs.imshow(grid, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946980d-344f-4660-8571-cbb74004479b",
   "metadata": {},
   "source": [
    "#### segmentation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddc9a1-3124-4730-b6c0-89a2d7a1f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load seg info \n",
    "## load segmentation functions\n",
    "seg_funcs = sc.load_segmentation_functions(fname=PATH_SEG_FUNCS)\n",
    "\n",
    "## segmentation config file \n",
    "config_fname =  \"./configs/example-config.yaml\"\n",
    "seg_config = sc.load_segmentation_config_from_file(fname=config_fname, seg_funcs=seg_funcs, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdd663-d206-45d6-9470-6e6708c6dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aicssegmentation.core import utils \n",
    "# utils.hole_filling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54943a5-63a5-4ab8-a3cb-e9f6c9c779ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "dct = yaml.safe_load(\"\"\"\n",
    "nuclei:\n",
    "    seg: \n",
    "        pipeline: \n",
    "            AC: \n",
    "                scaling_param: [0,15]\n",
    "            G2:\n",
    "                sigma: 3.5\n",
    "            MO: \n",
    "                object_minArea: 1000\n",
    "                global_thresh_method: ave_tri_med # tri, med, ave_tri_med\n",
    "            HF: \n",
    "                hole_min: 0\n",
    "                hole_max: 1200\n",
    "            #WD: {}\n",
    "            S:\n",
    "                min_size: 200\n",
    "                connectivity: 1\n",
    "        ops: \n",
    "            inplace: False\n",
    "\"\"\")\n",
    "seg_config[channel] = dct[channel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687d9a7-372b-4b62-9c90-36f9815fdc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b552425-6e2c-437c-9c04-79a79b10003f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cccc86-2998-4f86-8759-bcc8ff2de9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(sc)\n",
    "all_figs = []\n",
    "nlim = 100\n",
    "df_test = df_fnames_filt.iloc[::-1]\n",
    "for i, (idx, row) in enumerate(df_test.iterrows()):\n",
    "    if i>nlim:break\n",
    "    print(idx)\n",
    "    fname =row.path_file\n",
    "    ### record info about this file \n",
    "    print(fname)\n",
    "\n",
    "    f = plt.figure(figsize=(10,1)); plt.axis('off')\n",
    "    # plt.text(0.5,0.5,msg,ha='center',va='center', fontsize='xx-large', fontstretch='expanded')\n",
    "    all_figs.append(f)\n",
    "    plt.close()\n",
    "    \n",
    "    ### get the image and make a copy\n",
    "    img_in = imgs[lookup_idx_to_imgsidx[idx]]\n",
    "    img = img_in.copy()\n",
    "\n",
    "    ### segmentation params \n",
    "    show_whole_seg, show_sliding_window_masks, show_sliding_window = True, False, True\n",
    "    # Warning - this is only for display. \n",
    "    # The actual AC norm used in segmentation is the one listed in the YAML config file\n",
    "    ac_norm_params=[[0,15]]   \n",
    "    gs_smooth_params = [1,2]\n",
    "    es_smooth_params = [\n",
    "        dict(niter=5,kappa=1.2,gamma=0.1),\n",
    "    #     dict(niter=40,kappa=1.2,gamma=0.1)\n",
    "                       ]\n",
    "    # segmentation \n",
    "    seg, imgs_inter = sc.seg_2d(img[0], seg_config, seg_funcs, ch_name=channel, inplace=False, save_inters=True)\n",
    "\n",
    "    # show whole image\n",
    "    if show_whole_seg:\n",
    "        f, axs = plt.subplots(1,2,figsize=(20,20))\n",
    "        axs[0].imshow(img[0], cmap='gray')\n",
    "        axs[1].imshow(seg[0], cmap='gray')\n",
    "        plt.close()\n",
    "        all_figs.append(f)\n",
    "        display(f)\n",
    "\n",
    "    # sliding window params\n",
    "    window_sz, stride = 800, 800\n",
    "    min_pixels, figsize_mult, max_display_cols, do_plot_dividing_lines = 10, 7, 4, 5\n",
    "    f, show_mask, noshow_mask = pu.compare_seg_windows(img, seg, imgs_inter=imgs_inter,\n",
    "                                            max_display_cols=max_display_cols, figsize_mult=figsize_mult,do_plot_dividing_lines=do_plot_dividing_lines,\n",
    "                                            ac_norm_params=ac_norm_params,gs_smooth_params=gs_smooth_params, window_sz=window_sz, stride=stride,\n",
    "                                                      es_smooth_params=es_smooth_params)\n",
    "    all_figs.append(f)\n",
    "    display(f)\n",
    "    assert np.array_equal(img, img_in), \"Warning: the image got modified inplace somewhere\"\n",
    "\n",
    "    if show_sliding_window_masks:\n",
    "        f_tmp, axs = plt.subplots(1,2, figsize=(20,20))\n",
    "        axs[0].imshow(noshow_mask, cmap='gray');    axs[0].set(title=\"Ignored windows\")\n",
    "        axs[1].imshow(show_mask, cmap='gray')  ;    axs[1].set(title=\"Included widnows\")\n",
    "        display(f_tmp)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fea06-005d-4a05-9f2d-f3be4b90eefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d761b8-d5f0-4df6-897d-23bd2afc2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "fname_eval = PATH_EVALS / f\"{channel}-4samples.pdf\"\n",
    "with PdfPages(fname_eval) as pdf:\n",
    "    for f in all_figs:\n",
    "        pdf.savefig(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38cda9-6744-4575-93fa-f06026e158dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95595395-aff8-4938-898e-891f166bf760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d8b05-6df8-4a0b-bbc3-5615038d9b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825a393-70b7-46ae-8d96-8f782c9d02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH_DATA = Path(\"/pasteur/data/hiPSCs_January2022/\")\n",
    "PATH_FNAMES = PATH_DATA / \"fname-lookup-timelapse.csv\"\n",
    "import pandas as pd\n",
    "df_fnames = pd.read_csv(PATH_FNAMES).set_index('index')\n",
    "df_fnames['path_file'] = str(PATH_DATA) +\"/\"+ df_fnames['folder']+\"/\"+df_fnames['fname']\n",
    "# df_fnames=df_fnames.loc[[\"AP\" in s for s in df_fnames.index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb1e18-e8b8-45d3-a67b-d8d24b8bae93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a67cdc-7eab-4f90-bf7a-3848df9b1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fnames.query(\"g1 in ('D0','D7','D14','D21',)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bd1c8-1413-4836-8f54-1fef511e59a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fnames.loc[[\"AP\" in s for s in df_fnames.index]].g2.unique()\n",
    "for i, (idx, row) in enumerate(df_fnames.query(\"g2 in ('CTRL','CTRLAC','CTRLOAC')\").iterrows()):\n",
    "    print(i, row.path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85030a1b-6b22-449b-8634-b1559cbc8060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, row in df_fnames.iterrows():\n",
    "    print(i, row.path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba3bfff-b382-46cf-a8bb-de2074a454d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6cb26-df1b-4215-9ffd-1a6cef8351c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aicsimageio import AICSImage\n",
    "\n",
    "f=\"/pasteur/data/hiPSCs_January2022/Trial_ApoE-Knock-down-in-hiPSCs-undifferentiated/ApoE-Knock-Down-48hrs/48hrs-Ctrl_7_Unmixing.czi\"\n",
    "aics_img = AICSImage(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8742f-008d-44e7-83fe-c850a37962dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512f7ab-7328-48b9-b590-c44f259ff5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "f_img = \"/pasteur/data/hiPSCs_January2022/Differentiation-into-cortical-neuron_January2022/hiPSCs_KOLF2.1J_PB-TO-hNGN2clone1-TIME_LAPSE/hiPSCs-undifferentiated_day0/KOLF2.1J-PBTOhNGN2clone1-2_02_Unmixed.czi\"\n",
    "f_seg = \"/pasteur/data/hiPSCs_January2022/seg-framewise/feb23/Differentiation-into-cortical-neuron_January2022/hiPSCs_KOLF2.1J_PB-TO-hNGN2clone1-TIME_LAPSE/hiPSCs-undifferentiated_day0/KOLF2.1J-PBTOhNGN2clone1-2_02_Unmixed.czi\"\n",
    "\n",
    "f_img = \"/pasteur/data/hiPSCs_January2022/Trial_ApoE-Knock-down-in-hiPSCs-undifferentiated/ApoE-Knock-Down-48hrs/48hrs-Ctrl_+_oleic_acid_09_Unmixing.czi\"\n",
    "f_seg = \"/pasteur/data/hiPSCs_January2022/seg-framewise/feb23/Trial_ApoE-Knock-down-in-hiPSCs-undifferentiated/ApoE-Knock-Down-48hrs/48hrs-Ctrl_+_oleic_acid_09_Unmixing.czi\"\n",
    "\n",
    "aics_img = AICSImage(f_img)\n",
    "aics_seg = AICSImage(f_seg)\n",
    "img = aics_img.data\n",
    "seg = aics_seg.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff9c37-2443-4989-bb8c-7a52dc7e1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "aics_img.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f15874-98be-45b0-9da9-821c352d794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ch_names = aics_img.channel_names\n",
    "for i in range(8):\n",
    "    print(ch_names[i])\n",
    "    f,axs = plt.subplots(1,2,figsize=(10,10))\n",
    "\n",
    "    axs[0].imshow(img[0,i,10],cmap='gray')\n",
    "    axs[1].imshow(seg[0,i,10],cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b66e6-e6e2-44f7-9427-42b8cc1f7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
